{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "456bd7c62133d64a77fa64d50a41c1557c4e36a8"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2434
    },
    "colab_type": "code",
    "id": "zxktT22iAovZ",
    "outputId": "f9a05157-b60c-4ce4-aa11-b400a951c72f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: The conda.compat module is deprecated and will be removed in a future release.\r\n",
      "Collecting package metadata: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /opt/conda\r\n",
      "\r\n",
      "  removed specs:\r\n",
      "    - greenlet\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    conda-4.6.12               |           py36_1         2.1 MB\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:         2.1 MB\r\n",
      "\r\n",
      "The following packages will be REMOVED:\r\n",
      "\r\n",
      "  gevent-1.3.0-py36h14c3975_0\r\n",
      "  greenlet-0.4.13-py36h14c3975_0\r\n",
      "\r\n",
      "The following packages will be UPDATED:\r\n",
      "\r\n",
      "  conda                                       4.6.11-py36_0 --> 4.6.12-py36_1\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "conda-4.6.12         | 2.1 MB    | ##################################### | 100% \r\n",
      "Preparing transaction: \\ \b\bdone\r\n",
      "Verifying transaction: / \b\bdone\r\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "Collecting pytorch-pretrained-bert\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 5.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2.21.0)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.9.130)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (4.31.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.16.2)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (2019.3.12)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert) (1.0.1.post2)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert) (1.22)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (0.2.0)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.130 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert) (1.12.130)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (2.6.0)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (0.14)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.130->boto3->pytorch-pretrained-bert) (1.12.0)\r\n",
      "Installing collected packages: pytorch-pretrained-bert\r\n",
      "Successfully installed pytorch-pretrained-bert-0.6.1\r\n",
      "Collecting allennlp\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/c8/10342a6068a8d156a5947e03c95525d559e71ad62de0f2585ab922e14533/allennlp-0.8.3-py3-none-any.whl (5.6MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 5.6MB 6.5MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.6/site-packages (from allennlp) (3.0.3)\r\n",
      "Requirement already satisfied: numpydoc>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.8.0)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.1.0)\r\n",
      "Collecting awscli>=1.11.91 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e1/72c485a0c29c64b6d094b53a8eb03f39d8a4c2881bbf9b20aa5c32bd2318/awscli-1.16.141-py2.py3-none-any.whl (1.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 1.5MB 15.4MB/s \r\n",
      "\u001b[?25hCollecting responses>=0.7 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/5a/b887e89925f1de7890ef298a74438371ed4ed29b33def9e6d02dc6036fd8/responses-0.10.6-py2.py3-none-any.whl\r\n",
      "Collecting overrides (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/de/55/3100c6d14c1ed177492fcf8f07c4a7d2d6c996c0a7fc6a9a0a41308e7eec/overrides-1.9.tar.gz\r\n",
      "Collecting sqlparse>=0.2.4 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/53/900f7d2a54557c6a37886585a91336520e5539e3ae2423ff1102daf4f3a7/sqlparse-0.3.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: unidecode in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.23)\r\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.6/site-packages (from allennlp) (2018.4)\r\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.6/site-packages (from allennlp) (4.4.3)\r\n",
      "Collecting conllu==0.11 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/2c/856344d9b69baf5b374c395b4286626181a80f0c2b2f704914d18a1cea47/conllu-0.11-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: tqdm>=4.19 in /opt/conda/lib/python3.6/site-packages (from allennlp) (4.31.1)\r\n",
      "Collecting msgpack<0.6.0,>=0.5.6 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl (315kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 29.0MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: spacy<2.2,>=2.0 in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.1.3)\r\n",
      "Collecting gevent>=1.3.6 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/ca/5b5962361ed832847b6b2f9a2d0452c8c2f29a93baef850bb8ad067c7bf9/gevent-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (5.5MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 5.5MB 6.6MB/s \r\n",
      "\u001b[?25hCollecting flaky (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/02/42/cca66659a786567c8af98587d66d75e7d2b6e65662f8daab75db708ac35b/flaky-3.5.3-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (from allennlp) (3.2.4)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.9.130)\r\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.6/site-packages (from allennlp) (3.5.1)\r\n",
      "Collecting jsonnet>=0.10.0; sys_platform != \"win32\" (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/dc/3abd3971869a741d7acdba166d71d4f9366b6b53028dfd56f95de356af0f/jsonnet-0.12.1.tar.gz (240kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 28.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.9.0)\r\n",
      "Collecting word2number>=1.1 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\r\n",
      "Collecting editdistance (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/67/2b1fe72bdd13ee9ec32b97959d7dfbfcd7c0548081d69aaf8493c1e695f9/editdistance-0.5.3-cp36-cp36m-manylinux1_x86_64.whl (178kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 32.7MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.16.2)\r\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.6.1)\r\n",
      "Collecting moto>=1.3.4 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/40/cec89fa5c13108eb1c8de435633f8b7639e0e43fcbcdc8ac52633efeeabe/moto-1.3.7-py2.py3-none-any.whl (552kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 21.6MB/s \r\n",
      "\u001b[?25hCollecting flask-cors>=3.0.7 (from allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/65/cb/683f71ff8daa3aea0a5cbb276074de39f9ab66d3fbb8ad5efb5bb83e90d2/Flask_Cors-3.0.7-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: tensorboardX>=1.2 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.6)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.1.post2)\r\n",
      "Requirement already satisfied: requests>=2.18 in /opt/conda/lib/python3.6/site-packages (from allennlp) (2.21.0)\r\n",
      "Requirement already satisfied: flask>=1.0.2 in /opt/conda/lib/python3.6/site-packages (from allennlp) (1.0.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from allennlp) (0.20.3)\r\n",
      "Collecting parsimonious>=0.8.0 (from allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 24.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp) (2.2.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=2.2.3->allennlp) (2.6.0)\r\n",
      "Requirement already satisfied: sphinx>=1.2.3 in /opt/conda/lib/python3.6/site-packages (from numpydoc>=0.8.0->allennlp) (1.7.4)\r\n",
      "Requirement already satisfied: Jinja2>=2.3 in /opt/conda/lib/python3.6/site-packages (from numpydoc>=0.8.0->allennlp) (2.10)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.14)\r\n",
      "Requirement already satisfied: PyYAML<=3.13,>=3.10 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (3.12)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.2.0)\r\n",
      "Collecting botocore==1.12.131 (from awscli>=1.11.91->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/24/8e13f0c62e82fc4494f30913e4ff0bbc4e6dc38eed98bc9d7eaa7b9a9c61/botocore-1.12.131-py2.py3-none-any.whl (5.4MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 6.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: colorama<=0.3.9,>=0.2.5 in /opt/conda/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.3.9)\r\n",
      "Collecting rsa<=3.5.0,>=3.1.2 (from awscli>=1.11.91->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e1/ae/baedc9cb175552e95f3395c43055a6a5e125ae4d48a1d7a924baca83e92e/rsa-3.4.2-py2.py3-none-any.whl (46kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 23.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from responses>=0.7->allennlp) (1.12.0)\r\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.6/site-packages (from ftfy->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from ftfy->allennlp) (0.1.7)\r\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.2.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (1.0.0)\r\n",
      "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.6.0)\r\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.0.5)\r\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.9.6)\r\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.2.1)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.0.2)\r\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (7.0.4)\r\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.0.1)\r\n",
      "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\" (from gevent>=1.3.6->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 24.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->allennlp) (0.9.4)\r\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (1.5.3)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (39.1.0)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (18.1.0)\r\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (4.1.0)\r\n",
      "Requirement already satisfied: pluggy<0.7,>=0.5 in /opt/conda/lib/python3.6/site-packages (from pytest->allennlp) (0.6.0)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch-pretrained-bert>=0.6.0->allennlp) (2019.3.12)\r\n",
      "Requirement already satisfied: werkzeug in /opt/conda/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (0.14.1)\r\n",
      "Collecting xmltodict (from moto>=1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\r\n",
      "Collecting pyaml (from moto>=1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/33/1a/936074f3492156693fc9e471269fc5747fa3b7d9d7f8a33af054f6b24066/pyaml-19.4.1-py2.py3-none-any.whl\r\n",
      "Collecting docker>=2.5.1 (from moto>=1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/68/c3afca1a5aa8d2997ec3b8ee822a4d752cf85907b321f07ea86888545152/docker-3.7.2-py2.py3-none-any.whl (134kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 33.6MB/s \r\n",
      "\u001b[?25hCollecting python-jose<3.0.0 (from moto>=1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/5c/5fa238c0c5b0656994b52721dd8b1d7bf52ebd8786518dde794f44de86b6/python_jose-2.0.2-py2.py3-none-any.whl\r\n",
      "Collecting cryptography>=2.3.0 (from moto>=1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/12/b0409a94dad366d98a8eee2a77678c7a73aafd8c0e4b835abea634ea3896/cryptography-2.6.1-cp34-abi3-manylinux1_x86_64.whl (2.3MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 2.3MB 15.3MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: mock in /opt/conda/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.0.0)\r\n",
      "Requirement already satisfied: boto>=2.36.0 in /opt/conda/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.48.0)\r\n",
      "Collecting aws-xray-sdk<0.96,>=0.93 (from moto>=1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/a5/da7887285564f9e0ae5cd25a453cca36e2cd43d8ccc9effde260b4d80904/aws_xray_sdk-0.95-py2.py3-none-any.whl (52kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 27.1MB/s \r\n",
      "\u001b[?25hCollecting jsondiff==1.1.1 (from moto>=1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/5f/13e28a2f9abeda2ffb3f44f2f809b01b52bc02cdb63816e05b8c9cbbdfc5/jsondiff-1.1.1.tar.gz\r\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorboardX>=1.2->allennlp) (3.7.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (2019.3.9)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (1.22)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.18->allennlp) (2.6)\r\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/lib/python3.6/site-packages (from flask>=1.0.2->allennlp) (0.24)\r\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/lib/python3.6/site-packages (from flask>=1.0.2->allennlp) (7.0)\r\n",
      "Requirement already satisfied: Pygments>=2.0 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.2.0)\r\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.2.1)\r\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.5.3)\r\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (0.7.10)\r\n",
      "Requirement already satisfied: imagesize in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.0.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (17.1)\r\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /opt/conda/lib/python3.6/site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.0.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.6/site-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.0)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from html5lib->ftfy->allennlp) (0.5.1)\r\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.6/site-packages (from docker>=2.5.1->moto>=1.3.4->allennlp) (0.56.0)\r\n",
      "Collecting docker-pycreds>=0.4.0 (from docker>=2.5.1->moto>=1.3.4->allennlp)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\r\n",
      "Requirement already satisfied: future<1.0 in /opt/conda/lib/python3.6/site-packages (from python-jose<3.0.0->moto>=1.3.4->allennlp) (0.17.1)\r\n",
      "Collecting pycryptodome<4.0.0,>=3.3.1 (from python-jose<3.0.0->moto>=1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/fc/b09816d7b2d79d6454f75b40def94a89ed785d8d8d07840563f1084c6ecd/pycryptodome-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (9.7MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 9.7MB 1.3MB/s \r\n",
      "\u001b[?25hCollecting ecdsa<1.0 (from python-jose<3.0.0->moto>=1.3.4->allennlp)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/f4/73669d51825516ce8c43b816c0a6b64cd6eb71d08b99820c00792cb42222/ecdsa-0.13-py2.py3-none-any.whl (86kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 27.4MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (0.24.0)\r\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.6/site-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (1.11.5)\r\n",
      "Requirement already satisfied: pbr>=0.11 in /opt/conda/lib/python3.6/site-packages (from mock->moto>=1.3.4->allennlp) (5.1.3)\r\n",
      "Requirement already satisfied: jsonpickle in /opt/conda/lib/python3.6/site-packages (from aws-xray-sdk<0.96,>=0.93->moto>=1.3.4->allennlp) (0.9.6)\r\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.6/site-packages (from aws-xray-sdk<0.96,>=0.93->moto>=1.3.4->allennlp) (1.10.11)\r\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->allennlp) (2.18)\r\n",
      "Building wheels for collected packages: overrides, jsonnet, word2number, parsimonious, jsondiff\r\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/8d/52/86/e5a83b1797e7d263b458d2334edd2704c78508b3eea9323718\r\n",
      "  Building wheel for jsonnet (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/f0/47/51/a178b15274ed0db775a1ae9c799ce31e511609c3ab75a7dec5\r\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\r\n",
      "  Building wheel for parsimonious (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\r\n",
      "  Building wheel for jsondiff (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/68/08/07/69d839606fb7fdc778fa86476abc0a864693d45969a0c1936c\r\n",
      "Successfully built overrides jsonnet word2number parsimonious jsondiff\r\n",
      "Installing collected packages: botocore, rsa, awscli, responses, overrides, sqlparse, conllu, msgpack, greenlet, gevent, flaky, jsonnet, word2number, editdistance, xmltodict, pyaml, docker-pycreds, docker, pycryptodome, ecdsa, python-jose, cryptography, aws-xray-sdk, jsondiff, moto, flask-cors, parsimonious, allennlp\r\n",
      "  Found existing installation: botocore 1.12.130\r\n",
      "    Uninstalling botocore-1.12.130:\r\n",
      "      Successfully uninstalled botocore-1.12.130\r\n",
      "  Found existing installation: rsa 4.0\r\n",
      "    Uninstalling rsa-4.0:\r\n",
      "      Successfully uninstalled rsa-4.0\r\n",
      "  Found existing installation: msgpack 0.6.1\r\n",
      "    Uninstalling msgpack-0.6.1:\r\n",
      "      Successfully uninstalled msgpack-0.6.1\r\n",
      "  Found existing installation: cryptography 2.2.2\r\n",
      "    Uninstalling cryptography-2.2.2:\r\n",
      "      Successfully uninstalled cryptography-2.2.2\r\n",
      "  Found existing installation: Flask-Cors 3.0.4\r\n",
      "    Uninstalling Flask-Cors-3.0.4:\r\n",
      "      Successfully uninstalled Flask-Cors-3.0.4\r\n",
      "Successfully installed allennlp-0.8.3 aws-xray-sdk-0.95 awscli-1.16.141 botocore-1.12.131 conllu-0.11 cryptography-2.6.1 docker-3.7.2 docker-pycreds-0.4.0 ecdsa-0.13 editdistance-0.5.3 flaky-3.5.3 flask-cors-3.0.7 gevent-1.4.0 greenlet-0.4.15 jsondiff-1.1.1 jsonnet-0.12.1 moto-1.3.7 msgpack-0.5.6 overrides-1.9 parsimonious-0.8.1 pyaml-19.4.1 pycryptodome-3.8.1 python-jose-2.0.2 responses-0.10.6 rsa-3.4.2 sqlparse-0.3.0 word2number-1.1 xmltodict-0.12.0\r\n",
      "Collecting https://github.com/ceshine/pytorch_helper_bot/archive/0.0.5.zip\r\n",
      "  Downloading https://github.com/ceshine/pytorch_helper_bot/archive/0.0.5.zip\r\n",
      "\u001b[K     | 112kB 13.0MB/s\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from PyTorchHelperBot==0.0.5) (1.0.1.post2)\r\n",
      "Building wheels for collected packages: PyTorchHelperBot\r\n",
      "  Building wheel for PyTorchHelperBot (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-sqpeluqu/wheels/83/9c/cd/789072117df3c77e5fd6368c30b293947b88b92a44034fee3b\r\n",
      "Successfully built PyTorchHelperBot\r\n",
      "Installing collected packages: PyTorchHelperBot\r\n",
      "Successfully installed PyTorchHelperBot-0.0.5\r\n"
     ]
    }
   ],
   "source": [
    "!conda remove -y greenlet\n",
    "!pip install pytorch-pretrained-bert\n",
    "!pip install allennlp\n",
    "!pip install https://github.com/ceshine/pytorch_helper_bot/archive/0.0.5.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "98b461a0d1e2d27558502f9caefeaf7e47871efc",
    "colab_type": "text",
    "id": "9WAyYhZUAovT"
   },
   "source": [
    "\"pytorch_helper_bot\" is a thin abstraction of some common PyTorch training routines. It can easily be replaced, so you can mostly ignore it and focus on the preprocessing and model definition instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4e128e4337fd5c906540c112bc1d4e0fd2f38ef3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D24_hoPlAovh",
    "outputId": "aeffc30a-6828-46ea-b13e-a86de4d81eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# This variable is used by helperbot to make the training deterministic\n",
    "os.environ[\"SEED\"] = \"828\"\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "from allennlp.modules.span_extractors import SelfAttentiveSpanExtractor, EndpointSpanExtractor\n",
    "import re\n",
    "\n",
    "# import tokenization\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "from helperbot import (\n",
    "    TriangularLR, BaseBot, WeightDecayOptimizerWrapper,\n",
    "    GradualWarmupScheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4209e502d9d0c58575d71a7580cabc66bbf7ff70",
    "colab": {},
    "colab_type": "code",
    "id": "vlSb_17SAovo"
   },
   "outputs": [],
   "source": [
    "BERT_MODEL = 'bert-large-uncased'\n",
    "CASED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3302e69f42392d81362b53abceb3af54ac95b5d9",
    "colab": {},
    "colab_type": "code",
    "id": "LNfb110WEhXF"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\"The MLP submodule\"\"\"\n",
    "    def __init__(self, bert_hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.bert_hidden_size = bert_hidden_size\n",
    "        self.head_hidden_size = 256\n",
    "        # self.span_extractor = SelfAttentiveSpanExtractor(bert_hidden_size)\n",
    "        self.span_extractor = EndpointSpanExtractor(\n",
    "            bert_hidden_size, \"x,y,x*y\"\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(bert_hidden_size * 7),\n",
    "#             nn.Dropout(0.2),\n",
    "            nn.Linear(bert_hidden_size * 7, self.head_hidden_size),           \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(self.head_hidden_size),\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Linear(self.head_hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 3)\n",
    "        )\n",
    "        \n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.BatchNorm1d(bert_hidden_size * 7),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(bert_hidden_size * 7, self.head_hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(self.head_hidden_size),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(self.head_hidden_size, self.head_hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(self.head_hidden_size),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(self.head_hidden_size, self.head_hidden_size),\n",
    "#             nn.ReLU(),\n",
    "#             nn.BatchNorm1d(self.head_hidden_size),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(self.head_hidden_size, 3)\n",
    "#         )\n",
    "#         for i, module in enumerate(self.fc):\n",
    "#             if isinstance(module, (nn.BatchNorm1d, nn.BatchNorm2d)):\n",
    "#                 nn.init.constant_(module.weight, 1)\n",
    "#                 nn.init.constant_(module.bias, 0)\n",
    "#                 print(\"Initing batchnorm\")\n",
    "#             elif isinstance(module, nn.Linear):\n",
    "#                 if getattr(module, \"weight_v\", None) is not None:\n",
    "#                     nn.init.uniform_(module.weight_g, 0, 1)\n",
    "#                     nn.init.kaiming_normal_(module.weight_v)\n",
    "#                     print(\"Initing linear with weight normalization\")\n",
    "#                     assert model[i].weight_g is not None\n",
    "#                 else:\n",
    "#                     nn.init.kaiming_normal_(module.weight)\n",
    "#                     print(\"Initing linear\")\n",
    "#                 nn.init.constant_(module.bias, 0)\n",
    "                \n",
    "    def forward(self, bert_outputs, offsets):\n",
    "        assert bert_outputs.size(2) == self.bert_hidden_size\n",
    "        spans_contexts = self.span_extractor(\n",
    "            bert_outputs, \n",
    "            offsets[:, :4].reshape(-1, 2, 2)\n",
    "        ).reshape(offsets.size()[0], -1)\n",
    "        return self.fc(torch.cat([\n",
    "            spans_contexts,\n",
    "            torch.gather(\n",
    "                bert_outputs, 1,\n",
    "                offsets[:, [4]].unsqueeze(2).expand(-1, -1, self.bert_hidden_size)\n",
    "            ).squeeze(1)\n",
    "        ], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6d3c64ff3a19456ee88ef77825b83690e5907475",
    "colab": {},
    "colab_type": "code",
    "id": "lvTCFyWIAovs"
   },
   "outputs": [],
   "source": [
    "def tokenize(row, tokenizer):\n",
    "    break_points = sorted(\n",
    "        [\n",
    "            (\"A\", row[\"A-offset\"], row[\"A\"]),\n",
    "            (\"B\", row[\"B-offset\"], row[\"B\"]),\n",
    "            (\"P\", row[\"Pronoun-offset\"], row[\"Pronoun\"]),\n",
    "        ], key=lambda x: x[0]\n",
    "    )\n",
    "    tokens, spans, current_pos = [], {}, 0\n",
    "    for name, offset, text in break_points:\n",
    "        tokens.extend(tokenizer.tokenize(row[\"Text\"][current_pos:offset]))\n",
    "        # Make sure we do not get it wrong\n",
    "        assert row[\"Text\"][offset:offset+len(text)] == text\n",
    "        # Tokenize the target\n",
    "        tmp_tokens = tokenizer.tokenize(row[\"Text\"][offset:offset+len(text)])\n",
    "        spans[name] = [len(tokens), len(tokens) + len(tmp_tokens) - 1] # inclusive\n",
    "        tokens.extend(tmp_tokens)\n",
    "        current_pos = offset + len(text)\n",
    "    tokens.extend(tokenizer.tokenize(row[\"Text\"][current_pos:offset]))\n",
    "    assert spans[\"P\"][0] == spans[\"P\"][1]\n",
    "    return tokens, (spans[\"A\"] + spans[\"B\"] + [spans[\"P\"][0]])\n",
    "\n",
    "\n",
    "class GAPDataset(Dataset):\n",
    "    \"\"\"Custom GAP Dataset class\"\"\"\n",
    "    def __init__(self, df, tokenizer, labeled=True):\n",
    "        self.labeled = labeled\n",
    "        if labeled:\n",
    "            self.y = df.target.values.astype(\"uint8\")\n",
    "        \n",
    "        self.offsets, self.tokens = [], []\n",
    "        for _, row in df.iterrows():\n",
    "            tokens, offsets = tokenize(row, tokenizer)\n",
    "            self.offsets.append(offsets)\n",
    "            self.tokens.append(tokenizer.convert_tokens_to_ids(\n",
    "                [\"[CLS]\"] + tokens + [\"[SEP]\"]))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.labeled:\n",
    "            return self.tokens[idx], self.offsets[idx], self.y[idx]\n",
    "        return self.tokens[idx], self.offsets[idx], None\n",
    "\n",
    "    \n",
    "def collate_examples(batch, truncate_len=490):\n",
    "    \"\"\"Batch preparation.\n",
    "    \n",
    "    1. Pad the sequences\n",
    "    2. Transform the target.\n",
    "    \"\"\"    \n",
    "    transposed = list(zip(*batch))\n",
    "    max_len = min(\n",
    "        max((len(x) for x in transposed[0])),\n",
    "        truncate_len\n",
    "    )\n",
    "    tokens = np.zeros((len(batch), max_len), dtype=np.int64)\n",
    "    for i, row in enumerate(transposed[0]):\n",
    "        row = np.array(row[:truncate_len])\n",
    "        tokens[i, :len(row)] = row\n",
    "    token_tensor = torch.from_numpy(tokens)\n",
    "    # Offsets\n",
    "    offsets = torch.stack([\n",
    "        torch.LongTensor(x) for x in transposed[1]\n",
    "    ], dim=0) + 1 # Account for the [CLS] token\n",
    "    # Labels\n",
    "    if len(transposed) == 2:\n",
    "        return token_tensor, offsets, None\n",
    "    labels = torch.LongTensor(transposed[2])\n",
    "    return token_tensor, offsets, labels\n",
    "\n",
    "\n",
    "class GAPModel(nn.Module):\n",
    "    \"\"\"The main model.\"\"\"\n",
    "    def __init__(self, bert_model: str, device: torch.device, use_layer: int = -2):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.use_layer = use_layer\n",
    "        if bert_model in (\"bert-base-uncased\", \"bert-base-cased\"):\n",
    "            self.bert_hidden_size = 768\n",
    "        elif bert_model in (\"bert-large-uncased\", \"bert-large-cased\"):\n",
    "            self.bert_hidden_size = 1024\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported BERT model.\")\n",
    "        self.bert = BertModel.from_pretrained(bert_model).to(device)\n",
    "        self.head = Head(self.bert_hidden_size).to(device)\n",
    "    \n",
    "    def forward(self, token_tensor, offsets):\n",
    "        token_tensor = token_tensor.to(self.device)\n",
    "        bert_outputs, _ =  self.bert(\n",
    "            token_tensor, attention_mask=(token_tensor > 0).long(), \n",
    "            token_type_ids=None, output_all_encoded_layers=True)\n",
    "        head_outputs = self.head(bert_outputs[self.use_layer], offsets.to(self.device))\n",
    "        return head_outputs            \n",
    "\n",
    "\n",
    "# Adapted from fast.ai library\n",
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "\n",
    "            \n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))\n",
    "    \n",
    "    \n",
    "class GAPBot(BaseBot):\n",
    "    def __init__(self, model, train_loader, val_loader, *, optimizer, clip_grad=0,\n",
    "        avg_window=100, log_dir=\"./cache/logs/\", log_level=logging.INFO,\n",
    "        checkpoint_dir=\"./cache/model_cache/\", batch_idx=0, echo=False,\n",
    "        device=\"cuda:0\", use_tensorboard=False):\n",
    "        super().__init__(\n",
    "            model, train_loader, val_loader, \n",
    "            optimizer=optimizer, clip_grad=clip_grad,\n",
    "            log_dir=log_dir, checkpoint_dir=checkpoint_dir, \n",
    "            batch_idx=batch_idx, echo=echo,\n",
    "            device=device, use_tensorboard=use_tensorboard\n",
    "        )\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.loss_format = \"%.6f\"\n",
    "        \n",
    "    def extract_prediction(self, tensor):\n",
    "        return tensor\n",
    "    \n",
    "    def snapshot(self):\n",
    "        \"\"\"Override the snapshot method because Kaggle kernel has limited local disk space.\"\"\"\n",
    "        loss = self.eval(self.val_loader)\n",
    "        loss_str = self.loss_format % loss\n",
    "        self.logger.info(\"Snapshot loss %s\", loss_str)\n",
    "        self.logger.tb_scalars(\n",
    "            \"losses\", {\"val\": loss},  self.step)\n",
    "        target_path = (\n",
    "            self.checkpoint_dir / \"best.pth\")        \n",
    "        if not self.best_performers or (self.best_performers[0][0] > loss):\n",
    "            torch.save(self.model.state_dict(), target_path)\n",
    "            self.best_performers = [(loss, target_path, self.step)]\n",
    "        self.logger.info(\"Saving checkpoint %s...\", target_path)\n",
    "        assert Path(target_path).exists()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1f78b39f37426ab9a2643c4be09de4b6b466ac84",
    "colab": {},
    "colab_type": "code",
    "id": "TENyTChtCPqi"
   },
   "outputs": [],
   "source": [
    "def extract_target(df):\n",
    "    df[\"Neither\"] = 0\n",
    "    df.loc[~(df['A-coref'] | df['B-coref']), \"Neither\"] = 1\n",
    "    df[\"target\"] = 0\n",
    "    df.loc[df['B-coref'] == 1, \"target\"] = 1\n",
    "    df.loc[df[\"Neither\"] == 1, \"target\"] = 2\n",
    "    print(df.target.value_counts())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "d534c85ff69192b4dd1ec670fc9c2b9392cc7a62",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "-NT9XHDkAovw",
    "outputId": "bc403ee9-7f7b-4cc5-84fd-f7ed186f9803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1985\n",
      "0    1979\n",
      "2     490\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([\n",
    "    pd.read_csv(\"../input/gap-coreference/gap-test.tsv\", delimiter=\"\\t\"),\n",
    "    pd.read_csv(\"../input/gap-coreference/gap-validation.tsv\", delimiter=\"\\t\"),\n",
    "    pd.read_csv(\"../input/gap-coreference/gap-development.tsv\", delimiter=\"\\t\")\n",
    "], axis=0)\n",
    "\n",
    "df_test = pd.read_csv(\"../input/gendered-pronoun-resolution/test_stage_2.tsv\", delimiter=\"\\t\")\n",
    "df_train = extract_target(train_df)\n",
    "# df_test = extract_target(test_df)\n",
    "sample_sub = pd.read_csv(\"../input/gendered-pronoun-resolution/sample_submission_stage_2.csv\")\n",
    "# assert sample_sub.shape[0] == df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-69b278733491>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m  \u001b[0msample_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_df' is not defined"
     ]
    }
   ],
   "source": [
    "assert  sample_sub.shape[0] == test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d58d18c34f5df9ec8f8d8fb048ae6c10fbf9914a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Qu8XkjmNAov0",
    "outputId": "6fadb239-d6ca-4006-8f95-d31ec4414356",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 1150878.89B/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    BERT_MODEL,\n",
    "    do_lower_case=CASED,\n",
    "    never_split = (\"[UNK]\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "69689365738454b33649a14d83eea49cc1b18687",
    "colab": {},
    "colab_type": "code",
    "id": "z-Wx2NdAAov5"
   },
   "outputs": [],
   "source": [
    "test_ds = GAPDataset(df_test, tokenizer, labeled = False)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    collate_fn = collate_examples,\n",
    "    batch_size=128,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-0b2a07dfd2cf>\", line 70, in collate_examples\n    labels = torch.LongTensor(transposed[2])\nTypeError: an integer is required (got type NoneType)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5973a4007a84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-0b2a07dfd2cf>\", line 70, in collate_examples\n    labels = torch.LongTensor(transposed[2])\nTypeError: an integer is required (got type NoneType)\n"
     ]
    }
   ],
   "source": [
    "next(iter(test_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "391f4f961ee70ac7b2731a04afe9d45e5458d82f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11132
    },
    "colab_type": "code",
    "id": "3fn1H8nFBg2m",
    "outputId": "14ee0705-9440-4e79-a2a6-de9e6c50c95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Fold 1\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1248501532/1248501532 [00:35<00:00, 35164028.87B/s]\n",
      "[[04/17/2019 04:50:11 AM]] SEED: 828\n",
      "[[04/17/2019 04:50:11 AM]] # of paramters: 337,008,643\n",
      "[[04/17/2019 04:50:11 AM]] # of trainable paramters: 1,866,755\n",
      "[[04/17/2019 04:50:11 AM]] Optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 1e-06\n",
      ")\n",
      "[[04/17/2019 04:50:11 AM]] Batches per epoch: 445\n",
      "[[04/17/2019 04:50:11 AM]] ====================Epoch 1====================\n",
      "[[04/17/2019 04:50:37 AM]] Step 222: train 0.915136 lr: 1.000e-04\n",
      "[[04/17/2019 04:51:02 AM]] Step 444: train 0.788628 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:51:17 AM]] Snapshot loss 0.679731\n",
      "[[04/17/2019 04:51:19 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:51:19 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:51:20 AM]] ====================Epoch 2====================\n",
      "[[04/17/2019 04:51:46 AM]] Step 666: train 0.720669 lr: 1.000e-04\n",
      "[[04/17/2019 04:52:11 AM]] Step 888: train 0.681822 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:52:26 AM]] Snapshot loss 0.587600\n",
      "[[04/17/2019 04:52:28 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:52:28 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:52:29 AM]] ====================Epoch 3====================\n",
      "[[04/17/2019 04:52:54 AM]] Step 1110: train 0.630544 lr: 1.000e-04\n",
      "[[04/17/2019 04:53:19 AM]] Step 1332: train 0.625116 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:53:35 AM]] Snapshot loss 0.551609\n",
      "[[04/17/2019 04:53:37 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:53:37 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:53:37 AM]] ====================Epoch 4====================\n",
      "[[04/17/2019 04:54:02 AM]] Step 1554: train 0.598131 lr: 1.000e-04\n",
      "[[04/17/2019 04:54:28 AM]] Step 1776: train 0.602577 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:54:43 AM]] Snapshot loss 0.524371\n",
      "[[04/17/2019 04:54:46 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:54:46 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:54:46 AM]] ====================Epoch 5====================\n",
      "[[04/17/2019 04:55:11 AM]] Step 1998: train 0.575831 lr: 1.000e-04\n",
      "[[04/17/2019 04:55:36 AM]] Step 2220: train 0.575043 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:55:52 AM]] Snapshot loss 0.521975\n",
      "[[04/17/2019 04:55:54 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:55:54 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:55:54 AM]] ====================Epoch 6====================\n",
      "[[04/17/2019 04:56:19 AM]] Step 2442: train 0.553402 lr: 1.000e-04\n",
      "[[04/17/2019 04:56:45 AM]] Step 2664: train 0.552320 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:57:01 AM]] Snapshot loss 0.507131\n",
      "[[04/17/2019 04:57:03 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:57:03 AM]] New low\n",
      "\n",
      "[[04/17/2019 04:57:03 AM]] ====================Epoch 7====================\n",
      "[[04/17/2019 04:57:29 AM]] Step 2886: train 0.510924 lr: 1.000e-04\n",
      "[[04/17/2019 04:57:54 AM]] Step 3108: train 0.508793 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:58:09 AM]] Snapshot loss 0.514574\n",
      "[[04/17/2019 04:58:09 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:58:10 AM]] ====================Epoch 8====================\n",
      "[[04/17/2019 04:58:34 AM]] Step 3330: train 0.496196 lr: 1.000e-04\n",
      "[[04/17/2019 04:59:00 AM]] Step 3552: train 0.490317 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 04:59:16 AM]] Snapshot loss 0.511803\n",
      "[[04/17/2019 04:59:16 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 04:59:16 AM]] ====================Epoch 9====================\n",
      "[[04/17/2019 04:59:40 AM]] Step 3774: train 0.499131 lr: 1.000e-04\n",
      "[[04/17/2019 05:00:06 AM]] Step 3996: train 0.482757 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:00:22 AM]] Snapshot loss 0.507723\n",
      "[[04/17/2019 05:00:22 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:00:22 AM]] ====================Epoch 10====================\n",
      "[[04/17/2019 05:00:47 AM]] Step 4218: train 0.462466 lr: 1.000e-04\n",
      "[[04/17/2019 05:01:12 AM]] Step 4440: train 0.463316 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:01:28 AM]] Snapshot loss 0.499889\n",
      "[[04/17/2019 05:01:30 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:01:30 AM]] New low\n",
      "\n",
      "[[04/17/2019 05:01:30 AM]] ====================Epoch 11====================\n",
      "[[04/17/2019 05:01:55 AM]] Step 4662: train 0.469623 lr: 1.000e-04\n",
      "[[04/17/2019 05:02:21 AM]] Step 4884: train 0.469865 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:02:37 AM]] Snapshot loss 0.519217\n",
      "[[04/17/2019 05:02:37 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:02:37 AM]] ====================Epoch 12====================\n",
      "[[04/17/2019 05:03:01 AM]] Step 5106: train 0.441016 lr: 1.000e-04\n",
      "[[04/17/2019 05:03:26 AM]] Step 5328: train 0.436228 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:03:43 AM]] Snapshot loss 0.514928\n",
      "[[04/17/2019 05:03:43 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:03:43 AM]] ====================Epoch 13====================\n",
      "[[04/17/2019 05:04:07 AM]] Step 5550: train 0.450341 lr: 1.000e-04\n",
      "[[04/17/2019 05:04:32 AM]] Step 5772: train 0.416954 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:04:49 AM]] Snapshot loss 0.526942\n",
      "[[04/17/2019 05:04:49 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:04:49 AM]] ====================Epoch 14====================\n",
      "[[04/17/2019 05:05:13 AM]] Step 5994: train 0.406503 lr: 1.000e-04\n",
      "[[04/17/2019 05:05:38 AM]] Step 6216: train 0.441266 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:05:55 AM]] Snapshot loss 0.515109\n",
      "[[04/17/2019 05:05:55 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:05:55 AM]] ====================Epoch 15====================\n",
      "[[04/17/2019 05:06:19 AM]] Step 6438: train 0.421323 lr: 1.000e-04\n",
      "[[04/17/2019 05:06:44 AM]] Step 6660: train 0.397907 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:07:01 AM]] Snapshot loss 0.521910\n",
      "[[04/17/2019 05:07:01 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:07:01 AM]] ====================Epoch 16====================\n",
      "[[04/17/2019 05:07:25 AM]] Step 6882: train 0.386955 lr: 1.000e-04\n",
      "[[04/17/2019 05:07:50 AM]] Step 7104: train 0.381389 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:08:06 AM]] Snapshot loss 0.534285\n",
      "[[04/17/2019 05:08:06 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:08:07 AM]] ====================Epoch 17====================\n",
      "[[04/17/2019 05:08:31 AM]] Step 7326: train 0.381398 lr: 1.000e-04\n",
      "[[04/17/2019 05:08:56 AM]] Step 7548: train 0.403178 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:09:13 AM]] Snapshot loss 0.561725\n",
      "[[04/17/2019 05:09:13 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:09:13 AM]] ====================Epoch 18====================\n",
      "[[04/17/2019 05:09:36 AM]] Step 7770: train 0.369054 lr: 1.000e-04\n",
      "[[04/17/2019 05:10:01 AM]] Step 7992: train 0.371829 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:10:19 AM]] Snapshot loss 0.526941\n",
      "[[04/17/2019 05:10:19 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:10:19 AM]] ====================Epoch 19====================\n",
      "[[04/17/2019 05:10:42 AM]] Step 8214: train 0.358158 lr: 1.000e-04\n",
      "[[04/17/2019 05:11:08 AM]] Step 8436: train 0.393625 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:11:25 AM]] Snapshot loss 0.543865\n",
      "[[04/17/2019 05:11:25 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "[[04/17/2019 05:11:25 AM]] ====================Epoch 20====================\n",
      "[[04/17/2019 05:11:48 AM]] Step 8658: train 0.365497 lr: 1.000e-04\n",
      "[[04/17/2019 05:12:14 AM]] Step 8880: train 0.367904 lr: 1.000e-04\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:12:31 AM]] Snapshot loss 0.540449\n",
      "[[04/17/2019 05:12:31 AM]] Saving checkpoint cache/model_cache/best.pth...\n",
      "100%|██████████| 7/7 [00:14<00:00,  1.97s/it]\n",
      "[[04/17/2019 05:12:47 AM]] Confirm val loss: 0.4999\n",
      "  0%|          | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-0b2a07dfd2cf>\", line 70, in collate_examples\n    labels = torch.LongTensor(transposed[2])\nTypeError: an integer is required (got type NoneType)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5a707980b75d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mval_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confirm val loss: %.4f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mtest_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/helperbot/bot.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, loader, return_y)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                 \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 138, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"<ipython-input-5-0b2a07dfd2cf>\", line 70, in collate_examples\n    labels = torch.LongTensor(transposed[2])\nTypeError: an integer is required (got type NoneType)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=191)\n",
    "\n",
    "val_preds, test_preds, val_ys, val_losses = [], [], [], []\n",
    "for train_index, valid_index in skf.split(df_train, df_train[\"target\"]):\n",
    "    print(\"=\" * 20)\n",
    "    print(f\"Fold {len(val_preds) + 1}\")\n",
    "    print(\"=\" * 20)\n",
    "    train_ds = GAPDataset(df_train.iloc[train_index], tokenizer)\n",
    "    val_ds = GAPDataset(df_train.iloc[valid_index], tokenizer)\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        collate_fn = collate_examples,\n",
    "        batch_size=8,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        collate_fn = collate_examples,\n",
    "        batch_size=128,\n",
    "        num_workers=2,\n",
    "        pin_memory=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    model = GAPModel(BERT_MODEL, torch.device(\"cuda:0\"))\n",
    "    # You can unfreeze the last layer of bert by calling set_trainable(model.bert.encoder.layer[23], True)\n",
    "    set_trainable(model.bert, False)\n",
    "    set_trainable(model.head, True)\n",
    "#     set_trainable(model.bert.encoder.layer[23], True)\n",
    "#     set_trainable(model.bert.encoder.layer[22], True)\n",
    "                  \n",
    "#     optimizer = WeightDecayOptimizerWrapper(\n",
    "#         torch.optim.Adam(model.parameters(), lr=2e-3),\n",
    "#         0.05\n",
    "#     )\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,weight_decay=1e-6)\n",
    "    bot = GAPBot(\n",
    "        model, train_loader, val_loader,\n",
    "        optimizer=optimizer, echo=True,\n",
    "        avg_window=25\n",
    "    )\n",
    "    gc.collect()\n",
    "    steps_per_epoch = len(train_loader) \n",
    "    n_steps = steps_per_epoch * 20\n",
    "    bot.train(\n",
    "        n_steps,\n",
    "        log_interval=steps_per_epoch // 2,\n",
    "        snapshot_interval=steps_per_epoch,\n",
    "#         scheduler=GradualWarmupScheduler(optimizer, 20, int(steps_per_epoch * 4),\n",
    "#             after_scheduler=CosineAnnealingLR(\n",
    "#                 optimizer, n_steps - int(steps_per_epoch * 4)\n",
    "#             )\n",
    "#         )\n",
    "#         scheduler=TriangularLR(\n",
    "#             optimizer, 20, ratio=2, steps_per_cycle=n_steps)\n",
    "    )\n",
    "    # Load the best checkpoint\n",
    "    bot.load_model(bot.best_performers[0][1])\n",
    "    bot.remove_checkpoints(keep=0)    \n",
    "    val_preds.append(torch.softmax(bot.predict(val_loader), -1).clamp(1e-3, 1-1e-3).cpu().numpy())\n",
    "    val_ys.append(df_train.iloc[valid_index].target.astype(\"uint8\").values)\n",
    "    val_losses.append(log_loss(val_ys[-1], val_preds[-1]))\n",
    "    bot.logger.info(\"Confirm val loss: %.4f\", val_losses[-1])\n",
    "    test_preds.append(torch.softmax(bot.predict(test_loader), -1).clamp(1e-3, 1-1e-3).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "4964c9bdcae7cdd5db2d8878d534a4fa7c554be1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "9Qd6IyQ-w11i",
    "outputId": "0947f722-d2ce-403d-aac6-3b66fbee62f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4999286440511022]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "95a30126727db3ee19e9469d563196332ca0f815",
    "colab": {},
    "colab_type": "code",
    "id": "tptt3GhxWQWC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_preds = np.mean(test_preds, axis=0)\n",
    "final_test_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "8fb035aaaf7d4908067360984619abaf25ee7581",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sIdoG3PuWqhK",
    "outputId": "b11277cb-6003-4ef3-e75e-e05b2fb79e70"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b634c8c6e7ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_test_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'target'"
     ]
    }
   ],
   "source": [
    "log_loss(df_test.target, final_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "51b7e2335c8f9c1b821b6aeaba7c5122fe74530a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "VFeDfICvAowc",
    "outputId": "07da31ee-bce0-46d4-c745-35a101c4b9df"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-de00148cf523>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create submission file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_sub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_test_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"A\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NEITHER\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_sub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    420\u001b[0m                                          dtype=values.dtype, copy=False)\n\u001b[1;32m    421\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataFrame constructor not properly called!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "# Create submission file\n",
    "df_sub = pd.DataFrame(final_test_preds, columns=[\"A\", \"B\", \"NEITHER\"])\n",
    "df_sub[\"ID\"] = df_test.ID\n",
    "df_sub.to_csv(\"submission.csv\", index=False)\n",
    "df_sub.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernel - span.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
